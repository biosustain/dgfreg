---
title: "Hierarchical Bayesian regression modelling predicts biochemical rection energies and facilitates quantitative modelling of cell metabolism"
toc: true
resource_path: ["../"]
abstract: >
  The thermodynamic effect on a biochemical reaction depends principally
  on the standard-condition formation energies of the compounds that the
  reaction consumes and produces. The state of the art method for estimating
  these parameters involves a statistical model called group contribution.
  We highlight a problem with group contribution: it typically produces a
  rank-deficient uncertainty covariance matrix. We present a new model that
  avoids this issue, generates more accurate estimates than the current state
  of the art and has unlimited reaction coverage. Our model includes parameters
  for both chemical groups and compounds, using a hierarchical component to
  balance information pertaining to these two levels, and addresses the issue
  of stoichiometric collinearity using QR decomposition. We provide a Gaussian
  approximation to our model's posterior distribution that can be used for
  downstream modelling. Our results can be replicated by
  following the instructions at <https://github.com/biosustain/dgfreg>.
author: 
  - name: "Teddy Groves"
    orcid: 0000-0002-7109-3270
    email: tedgro@biosustain.dtu.dk
    affiliation: DTU Biosustain
  - name: "Jason Jooste"
    affiliation: CSIRO
  - name: "Lars Keld Nielsen"
    affiliation: DTU Biosustain
bibliography: bibliography.bib
format:
  html: 
    include-in-header: mathjax.html
    embed-resources: true
  docx: default
  pdf: default
---

<!--Macros-->
::: {.hidden}
$$
\newcommand{\dgr}{\Delta_r}
\newcommand{\dgf}{\Delta_f}
\newcommand{\dgg}{\Delta_g}
$$
:::
<!--End Macros-->

# Introduction {#sec-introduction}

## Estimation of thermodynamic properties \label{sec-dgr-dgf-estimation}

Reaction thermodynamics play an essential role in the accurate modelling of metabolic processes and are used to determine the the direction in which a chemical reaction proceeds.
The Gibb's energy of a reaction (also referred to as the Gibb's *free* energy of reaction) represents the amount of usable energy released by a reaction.
As it is a state function, the Gibbs energy of a reaction $\dgr G$ is solely a function of the Gibb's energy of formation $\dgr G$ of its substrates.
This law can be conveniently represented in linear algebraic form as:
\begin{align}
\dgr G &= \vec{s}^\top\cdot \dgf G \label{eq-dgr-dgf-law}

\end{align}
where $\vec{s}\in\mathbb{R}^n$ represents the stoichiometries of the substrates of the reaction.

The Gibbs energy of a rection under standard conditions ($\Delta_r G^\degree$) has been recorded experimentally through the measurement of the equilibrium constants of a large number of common metabolic reactions and is related to the standard Gibbs energy of formation ($\Delta_f G^\degree$) of its substrates as per \eqnref{eq-dgr-dgf-law}. 
For ease of notation, we refer herein to the reaction and formation energies under standard conditions simply as $\dgr$ and $\dgf$ respectively.
Measuring $\dgf$ is more difficult, but has been performed for a small number of compounds. <!--Which ones?-->
These measurements are available in a number of different datasets @goldbergThermodynamicsEnzymecatalyzedReactions2004. <!--TECR DB + equilibrator. Others?-->
<!--Who. Albery?--> Was able to considerably extend the reach of these datasets using what @noorConsistentEstimationGibbs2013 refers to as the Reactant Contribution (RC) method. 
This method accurately estimates the standard Gibbs energies of formation $\dgf G^\degree$ of the substrates of reactions in the database by fitting a linear regression model. 
More formally, given a set of $n$ measurements $y\in\mathbb{R}^n$ of the standard reaction energies $\dgr G^\degree$ of $r$ reactions' standard condition Gibbs energy changes and a stoichiometric matrix $S\in\mathbb{R}^{m\times r}$ providing the stoichiometric coefficients of $m$ compounds in each measured reaction and a vector of errors $\epsilon_m \in \mathbb{R}^{n}$, formation energies can be estimated using the generative model in equation \eqref{eq-reactant-contribution}.

\begin{align}
y &= S^\top\cdot \dgf G^\degree + \epsilon_m \label{eq-rc} \\
\epsilon_m &\sim N(\hat{y}_i, \sigma) \nonumber
\end{align}

where N(\mu, \sigma) follows the Stan notation, with mean $\mu$ and standard deviation $\sigma$.
This also allows one to estimate $\dgr G^\degree$ for unmeasured reactions, as long as they only involve metabolites present in the model. 
Unfortunately, in many cases, $\dgf$ cannot be estimated using RC because they do not participate in any measured reactions and $\dgr$ of many reactions cannot be estimated because they involve at least one substrate not in the dataset. 

The group contribution (GC) model addresses the reactant contribution model's lack of coverage by instead modelling the formation energies of compounds as the sum of a set of predetermined chemical groups.
The group contribution model adds to the model in equation \eqref{eq-rc} the group additivity assumption \eqref{eq-group-additivity}, according to which a compound's formation energy is the stoichiometry-weighted sum of the formation energies of its constituent groups, i.e. the 'group contribution' model.
In equation \eqref{eq-group-additivity}, $\mathbf{G}\in\mathbb{R}^{m\times g}$ is a group incidence matrix that maps combinations of $m$ compounds and $g$ groups to stoichiometric coefficients and $\dgg$ is a vector of $g$ group formation energies.

\begin{equation}
\dgf = \mathbf{G}\cdot\dgg G^\degree \label{eq-group-additivity}
\end{equation}

As with $\dgr$ and $\dgf$, and because group matrix symbol $\mathbf{G}$ and the 'G' of the standard group energies $\dgg G^\degree$ can be easily confused, we refer herein to the standard group energies with $\dgg$. 
Ideally, a linear regression would be performed following the above equation with data on the formation energies of various compounds. 
However, to make use of the more prevalent $\dgr$ measurements, the linear regression relates $\dgr$ to group estimates:

\begin{align}
\dgr &= S^{T}\cdot \mathbf{G} \dgg + \epsilon \label{eq-gc} \\ \epsilon &\sim N(0, \sigma) \nonumber
\end{align}

Two things are of note here.
Firstly, these two linear regressions represent fundamentally different relationships.
\eqref{eq-rc} represents a fundamental physical law, while \eqref{eq-gc} represents a statistical approximation of a property that we desire to predict. 
Relatedly, that \epsilon represents both the measurement error $\epsilon_m$ of \eqref{eq-reactant-contribution} but also error that results from an incomplete model of formation energies, which we refer to herein as model error $\epsilon_o$.
That is, $\epsilon = \epsilon_m + \epsilon_o$. 

Using this model's estimates $\hat{\dgg}$ for the parameters $\Delta _gG$, the formation energy of an unmeasured compound involving groups $\vec{p}\in \mathbb{R}^g$ and the reaction energy of an unknown reaction with stoichiometry $\vec{q}\in \mathbb{R}^m$ can be calculated as follows
\begin{align}
\hat{\dgf} &= \vec{p}\cdot \hat{\dgg}\label{eq-gc-prediction} \nonumber \\
\hat{\dgr} &= \vec{q}\cdot \mathbf{G} \hat{\dgg} \nonumber
\end{align}

Additionally, @noorConsistentEstimationGibbs2013 proposes the use of formation energy estimates from the more-accurate RC model where possible, falling back to estimates from the GC model for unmeasured compounds composed of measured groups.
This method is known as the 'component contribution' model.
While there have been more recent efforts to more accurately capture the effect of experimental conditions, as described in @duEstimatingMetabolicEquilibrium2018 and @beberEQuilibratorPlatformEstimation2021, the component contribution model remains the state of the art for estimating standard condition biochemical formation energies.

<!--SECTION ON COVARIANCE ESTIMATION-->

## Theoretical problems with the Group Contribution model {#sec-theoretical-problems-with-the-group-contribution-model}

There are a number of theoretical and practical limiations to the group contribution model shown in \eqref{eq-gc}, all of which are related to how the model partitions variance.
This estimate of the Gibbs energy of reaction has three sources of error: the error in the estimate $\hat{\dgg}$, which is normally distributed, the measurement error (usually assumed to be normally distributed) and finally the error that arises from model misspecification.
That is: 

\begin{align} 
cov(\hat{\dgg}) &= (\sigma_m^2 + \sigma_o^2)((S\mathbf{G})^\top (S\mathbf{G}))^{-1} \nonumber \\
var(\epsilon_m) &= \sigma_m^2 \nonumber \\
var(\epsilon_o) &= \sigma_o^2 \nonumber
\end{align}

As the amount of data increases, the estimation error decreases but the other two sources of error remain constant.
For comparison, the reactant contribution model in \eqreq{eq-rc} only has two sources of error: estimate error and measurement error.
Model misspecification error does not apply because the additive relationship between $\dgr$ and $\dgf$ is a known physical law and true by definition.
The problem stems from the fact that model mispecification errors are inherently a result of problems in the group contribution model and not the relationship between $\dgr$ and $\dgf$, yet the model is fit with additive errors on $\dgr$.
This has a number of consequences.
Firstly, it leads to violations in \eqref{eq-dgr-dgf-law}.
For example, if we assume known measurements and parameters for the reactions A and B, both of which involve metabolites C and D, we get the following equation: \begin{align} dgr = S^\top \mathbf{G} \dgg + \epsilon_m \end{align} with realised values for $epsilon_m$ of x and y.
However, C and D are not random variables giving $C-D\neq A$ and $C-D\neq B$.

Another consequence is the reduced degrees of freedom of $\dgf$.
Because the group matrix $\mathbf{G}$ necessarily has fewer groups than metabolites, $\dgf$ has degrees of freedom equivalent to Rank($\mathbf{G}$), which does not allow support for the full range of formation energies.
For example, metabolites C and D are composed of the same groups G, E and F.
The group contriubtion model defines these metabolites as having the same formation energy.
This considerably reduces the expressiveness of the model in the space of formation energies.
Furthermore, because errors in group contribution are fundamentally errors at the level of $\dgf$ estimation, the group contribution model does not meet the assumption of iid $\epsilon$.
For example, reactions that involve metabolites that are underestimated will have correlated, likely positive, residuals.
This is explained further in @sec-model-misspec.

Another problem is related to compounds that have the same group composition.
Suppose two compounds $a$ and $b$ have the same group composition $\vec{g}_{ab}$.
Then the group contribution estimate for compound $a$ is necessarily equal to the group contribution estimate for compound $b$, i.e.

<!--Same as above, I think we should start with the dgr estimate here (that is the true model that is fit, after all) and then move on to dgf. Also I think it should be clear that we're not stating this as fact, but that we're either quoting the authors or working within the limitations of the model formulation-->

\begin{equation}
\hat{\dgf}_a=\vec{g}_{ab}\cdot\hat{\dgg}=\hat{\dgf}_b \label{eq-group-contribution-problem}
\end{equation}

This implies that a reaction $j$ with stoichiometry $\vec{s}_j$ that converts $a$ into $b$ or vice versa will always have estimated standard condition Gibbs energy change $\hat{\dgr}_j$ zero according to the group contribution model.
According to equation \eqref{eq-thermodynamic-effect}, the group contribution model will therefore imply that the direction of reaction $j$ depends only on the sign of the term $1 - \exp(RT \cdot \frac{\vec{s}_j^\top\cdot\ln c}{RT})$, so that $v > 0$ if and only if $|a| < |b|$.

This feature of the group contribution model also leads to a more practical modelling problem.
If $\dgg$ is estimated by maximum likelihood estimation, the covariance matrix of the estimator vector $\hat{\dgf}=\mathbf{G}\hat{\dgg}$, as proposed in @beberEQuilibratorPlatformEstimation2021, is given by equation \eqref{eq-group-contribution-rank}:

\begin{equation}
Cov(\hat{\dgf}) = \mathbf{G} \cdot Var(\hat{\dgg}) \cdot \mathbf{G}^\top \label{eq-group-contribution-rank}
\end{equation}

This covariance matrix has the same rank as $\mathbf{G}$ since for $A=B\cdot C$, $rank(A)=min(rank(B), rank(C))$.
Therefore, in the typical case where the number of groups $g$ is less than the number of compounds $m$, the covariance matrix $Cov(\hat{\dgf})$ is guaranteed to be rank-deficient.
If $Cov(\hat{\dgf})$ is used as the covariance matrix of a multivariate normal prior distribution in a Bayesian mechanistic metabolic model, the resulting posterior distribution will assign zero probability mass to some regions of $\dgf$ space.
If the true parameter allocation lies in such a region, the model will be irreparably biased and will also likely suffer from computational issues due to an unresolvable conflict between prior and likelihood.

# Methods {#sec-methods}

We begin with @sec-improved-group-contribution-model, which describes an alternative statistical model of the eQuilibrator data that addresses the rank deficiency issue more comprehensively.
Later, we describe how this model can be applied to predicting out-of-sample reactions and predictions in @sec-unmodelled-compounds and then the data and methods used to compare the new model to the component contribution model in @sec-case-study.

## Hierarchical Group Contribution model {#sec-improved-group-contribution-model}

The proposed change to the group contribution model is in fact very simple. 
A vector of independent random variables $\vec{\eta}\in\mathbb{R}^m$ is simply added to the group contribution formation energy estimate in order to quantify the model error, allowing $\eta$ to represent purely the measurement error.
The generative Bayesian model, which we refer to as Hierarchical Group Contribution (HGC) is described as follows:

\begin{align}
\bar{y}_j &\sim N(\dgr, \frac{\sigma}{size(j)}) \label{eq-group-contribution-improved} \\
\dgr &= S^\top\cdot \dgf \nonumber \\
\dgf &= \mathbf{G}\cdot\dgg + \vec{\eta} \nonumber
\end{align}

In order to formulate a Bayesian model, priors need to be determined for the parameters.
This is realised by augmenting the generative model in equation \eqref{eq-group-contribution-improved} with the prior distributions in equation \eqref{eq-component-contribution-improved}:

\begin{align}
\vec{\eta} &\sim N(0, \tau) \label{eq-component-contribution-improved} \\
\dgg &\sim N(0, 5000) \nonumber \\
\tau &\sim HN(0, 3) \nonumber \\
\sigma &\sim HN(0, 3) \nonumber \\
\end{align}

In equation \eqref{eq-component-contribution-improved} $HN$ represents the non-negative half-normal distribution, i.e. the distribution with normal distribution densities for non-negative numbers and zero density for negative numbers.

The prior distribution for the group formation energy vector $\dgg$ is uninformative, whereas those for $\tau$, $\sigma$ and $\eta$ are informative.
In particular, the prior distribution for $\eta$ is hierarchical as it involves the random variable $\tau$.
This allows us to estimate the general accuracy of the group additivity assumption from the data: larger values of $\tau$ will allow weaker coupling between compound and group formation energies.
This model structure is appropriate given the available information.
In general there is very little prior information available about group formation energies, but there is information about measurement accuracy and the likely accuracy of the group additivity assumption.

In this model $Cov(\hat{\dgf})$ is guaranteed to be full rank, as $diag_m(\tau)$ is full rank and \eqref{eq-dgr-dgf-law} is satisfied, with any errors in GC estimation, correctly applied before transformation with $S^T$.
The model, and prior distributions based on it, will therefore avoid the computational and theoretical issues and discussed in @sec-theoretical-problems-with-the-group-contribution-model.
<!--yes!-->

## Estimating formation energies of unmeasured or unmodelled compounds {#sec-unmodelled-compounds}

Using our approach it is possible to estimate the formation energy of any
compound, regardless of whether the compound was measured or explicitly
included in our model. 
The procedure for doing this is as follows.

1. If the compound was included in the model, generate estimates using the marginal posterior samples for that compound as described above in equation \eqref{eq-qr-recovery}.
2. If the compound was not included in the model, but is composed of included groups, then generate draws for the variable $\prescript{}{new}{\eta}\in\mathbb{R}$ based on the marginal posterior samples for $\tau$, using the assumption $\prescript{}{new}{\eta}\sim N(0, \tau)$.
Now recover $\prescript{}{new}{\dgf}$ as in \eqref{eq-qr-recovery}.
3. If the compound was not included in the model and is partly or wholly composed of ${g}$ un-modelled groups, generate draws for the missing group parameters $\prescript{}{new}{\vec{q}}\in\mathbb{R}^{g}$ based on the prior distribution for $\vec{q}$.
Next find $\prescript{}{new}{\dgg}$ using equation \eqref{eq-qr-recovery}, then generate $\prescript{}{new}{\eta}$ and recover $\prescript{}{new}{\dgf}$ using the same method as for Case 2.

While it is possible, using this procedure, to generate formation energy estimates for any compounds consistently with the information and assumptions in our model, the accuracy of the resulting estimates is limited by the information about the unmeasured or unmodelled compounds in the training data.
In particular, formation energy estimates for compounds that include unmeasured chemical groups will typically be very wide, as our model assumes that there is little information available about the parameters $\vec{q}_{new}$.
We quantify the uncertainty of these different kinds of predictions in @sec-case-study.

In order to use our model results for downstream modelling, for example as a prior distribution for thermodynamic parameters in a Bayesian kinetic model, we suggest fitting a multivariate normal distribution to our model's posterior $\dgf$ parameter samples.
The fit of our model is provided the resulting tables in [TODO: SAY WHERE].
The code that produced these tables is available at [TODO: SAY WHERE].

<!--Can we talk about how well they fit? Some measure of how well our samples actually fit this normal distribution?-->

## Model evaluation {#sec-case-study}

In order to test the model, we used the data of @noorConsistentEstimationGibbs2013 extracted from the python equilibrator API for model training and evaluation.
This dataset is especially amenable to model training as extensive work, as described in @noorConsistentEstimationGibbs2013, has already been applied into adjusting a wide range of data to standard conditions. 
Additionally, as a reference for metabolites and reactions of particular importance, we used the *e coli* core model of @orthReconstructionUseMicrobial2010 as provided in cobraPY @ebrahimCOBRApyCOnstraintsBasedReconstruction2013. 
In order to compare our new model with the state of the art, we compared our estimates to those of Equilibrator when fit on the entire component contribution dataset, and under cross-validation. 
We excluded from the test dataset all measurements of reactions involving the compounds Acetyl CoA, PEP and G6P.
There were 33 such reactions and 370 measurements.

# Results

## Quantification of model misspecification {#sec-model-misspec}


In this section, we explore the dataset for instances of model misspecification and compare the fits of the GC, RC and HGC models with respect to the problems expounded in @sec-theoretical-problems-with-the-group-contribution-model. We begin by enumerating the reactions in the ecoli core model with no group changes and then explore the correlation between GC residuals, eta and compound etsimation error. 

The equilibrator dataset is composed of $3999$ measurements of $676$ reactions with $631$ substrates and has a rank of 502.
The $G$ matrix maps the $631$ substrates to $213$ with a rank of $144$ and the group change of reactions $S^\top G$ has rank 134.  
Since there are multiple possible decompositions of compounds into chemical groups, it is not possible to say in general which reactions are affected by the issue we highlight with the group contribution model.
Nevertheless, when observing the reactions of the *e coli* core model with the group matrix of Equilibrator we found 82 group-conserving reaction in the training dataset, 11 of which are also in the `e_coli_core` model.
These reactions are shown below in @tbl-bad-reactions.

| description                                                                                                                    | EC number|
|--------------------------------------------------------------------------------------------------------------------------------|----------|
| alpha-D-Glucose 6-phosphate(aq) = beta-D-Glucose 6-phosphate(aq)                                                               | 2.7.4.3  |
| 3-phosphonooxypyruvate(aq) + L-glutamate(aq) = 2-oxoglutarate(aq) + O-phospho-L-serine(aq)                                     | 2.7.1.40 |
| UDPglucose(aq) = UDPgalactose(aq)                                                                                              | 1.6.1.1  |
| 2'-deoxyinosine(aq) + adenine(aq) = 2'-deoxyadenosine(aq) + hypoxanthine(aq)                                                   | 5.3.1.9  |
| 3-phosphonooxypyruvate(aq) + L-glutamate(aq) = 2-oxoglutarate(aq) + O-phospho-L-serine(aq)                                     | 5.3.1.6  |
| UDPglucose(aq) = UDPgalactose(aq)                                                                                              | 4.2.1.2  |
| N-succinyl-2-L-amino-6-oxoheptanedioate(aq) + L-glutamate(aq) = N-succinyl-L-2,6-diaminoheptanedioate(aq) + 2-oxoglutarate(aq) | 1.1.1.42 |
| 3-phosphonooxypyruvate(aq) + L-glutamate(aq) = 2-oxoglutarate(aq) + O-phospho-L-serine(aq)                                     | 4.1.3.1  |
| L-aspartate(aq) + 2-oxoglutarate(aq) = oxaloacetate(aq) + L-glutamate(aq)                                                      | 4.2.1.3  |
| L-alanine(aq) + hydroxypyruvate(aq) = L-serine(aq) + pyruvate(aq)                                                              | 4.1.2.13 |
| ATP(aq) + GDP(aq) = ADP(aq) + GTP(aq)                                                                                          | 4.2.1.11 |

: Reactions in the `e_coli_core` model that conserve chemical groups according to the `equilibrator-api` group decomposition matrix, implying that their standard Gibbs energy of reaction is exactly zero according to the group contribution model.
{#tbl-bad-reactions}

As the relationship between $\dgf$ and $\dgr$ is a known physical property, we suspected that there may infact be correlation between the residuals of the group contribution model related to their shared metabolites.
That is, the true error for GC $\hat{\dgr}$ is contained in deviations from true $\dgf$ values, and thus that the residuals will not satisfy the assumption that the elements of $\epsilon$ in \eqref{eq-group-contribuion-final-estimate} are *i.i.d*. 
We should this relationship by first identifyng the deviation of GC dgf prediction from the true value. 
As we do not have access to this value, we instead approximate it with the RC dgf estimates, which are known to be extremely accurate. 
We then derive a measure of how much these differences have contributed to the prediction error by transforming them with the stoichiometric matrix:
<!--TODO: ENTER EQN HERE-->

As shown in @fig-cc-gc-diff-corr, we find that the residuals of the GC model fit are highly correlated with these deviations, suggesting $\dgf$ errors as the true source of error.
Furthermore, we find that $\eta$ estimates are highly correlated with these deviations, suggesting that the HGC model is absorbing some of the prediction variance into $\eta$ as expected. 
This is shown clearly in @fig-eta-cc-gc-diff-corr.
This is further demonstrated by the estimated error scales of the various models.
The HGC estimate of sigma is $\hat{\sigma_{hgc}}~=3.49$, compared to the estimated measurement error $\hat{\sigma_{rc}}~=2.749$ of the RC model than that of the group contribution model $\hat{\sigma{gc}}~=7.6$. 
All of the above suggests a migration of the variance from the noise term $\epsilon$ to the formation energy error $\eta$. 

::: {layout-ncol=2}
![Correlation between GC dgf error and residuals](plots/tfm-mean-GC-err-resid-corr.png){#fig-cc-gc-diff-corr}

![Correlation between $\eta$ and dgf error and residuals](plots/eta-GC-err-corr.png){#fig-eta-cc-gc-diff-corr}
:::

## Assessment of HGC model specification

To assess model specification we performed a posterior predictive check as shown in @fig-marginal-ppc. 
Our model's 1%-99% marginal posterior predictive distributions contained the measured value for approximately 98% of measurements, with no particular patterns in the deviations, indicating a reasonable model specification.<!-- Isn't exactly the number that we would expect in this window?-->
@fig-ppc-kde shows that our model was able to achieve a good fit despite a somewhat unbalanced distribution of measurements.<!-- What is meant by unbalanced measurements here?-->

<!--Could these metrics be applied to the base model? It might not perform as well-->

<!--Absolutely no idea why, but caption (and reference) generation only works in this order-->
![Overall posterior predictive check](plots/ppc_kde.svg){#fig-ppc-kde}

![Posterior predictive check](plots/marginal_ppc.svg){#fig-marginal-ppc}

<!--This needs better axis labels. y / yrep is a bit unintuitive (I first read it as division). This is a kernel density plot, right?-->

## Posterior distributions of interesting parameters {#sec-posterior-distributions-of-interesting-parameters}

@fig-posteriors shows the posterior distributions in our model for the parameters $\mu$, $\tau_{compound}$ and $\tau_{group}$, alongside these parameters' prior distributions.
The plots show that the model was able to reconcile the data with our prior information, though it made $\tau_{group}$ somewhat higher than we expected.
<!--Remove the value judgement here?-->
<!--Are tau_compound and tau_group still the going terms?-->

<!--TODO: This fig needs to be updated with info from both-->
![Posterior distributions of univariate model parameters](plots/posteriors.svg){#fig-posteriors}

## Comparison with component contribution

Overall our model produced similar formation energy estimates with somewhat larger marginal uncertainties compared with the component contribution model.
<!--TODO: Compare this with the *correct* formulation of the model (i.e. with the eps included)-->
This can be seen from figure @fig-estimate-comparison, which shows the marginal 1%-99% posterior intervals for our model alongside the 1%-99% quantiles of the corresponding component contribution uncertainty intervals.
Note that these plots are normalised based on the central component contribution estimate.
The fact that the red horizontal lines center on the black vertical line indicates that our model's central estimates tend to be very close to those of the component contribution model.

![Comparison of component contribution estimates with our model](plots/marginal_dgf_comparison.svg){#fig-estimate-comparison}

@fig-marginal-hist-widths shows histograms of the 1%-99% marginal posterior widths for our model and the component contribution model.
It shows more explicitly than @fig-estimate-comparison that the new model tends to produce more uncertain marginal formation energy estimates than the component contribution model.

<!--TODO: Dashed lines for means and thinner-->
![Comparison of component contribution uncertainty interval widths with our model](plots/marginal_width_hists.svg){#fig-marginal-hist-widths}

To compare model fit between our model and the component contribution model we found, for each measurement in the full dataset, the residual for the component contribution $\dgr$ as well as the residual for our model's marginal posterior predictive mean.
A histogram of the results is shown in @fig-residuals-full-dataset, as well as the overall root mean squared error for each model.
These results show that the two models achieved about the same level of fit to the data, with our model achieving slightly smaller errors on average.
<!--Mention RMSE values in text here?-->
<!--TODO: Better caption-->

![Comparison of residuals](plots/in_sample_rmse_comparison.svg){#fig-residuals-full-dataset}

## Out of sample predictions
<!--This needs an intro sentence-->
The RMSE on test measurements for component contribution was 43.28 for component contribution compared with 16.70 for our model.
However, this figure is somewhat misleading as it is dominated by a single outlier measurement of the phosphoenolpyruvate mutase reaction.
There is little information about this reaction in the test dataset, whose marginal posterior predictive interval in our model spans a range of about 4500 kJ/mol.
The component contribution model predicts a value of 771 kJ/mol, whereas our model's posterior predictive mean was 235 kJ/mol and the measured value was -28 kJ/mol.
Excluding this measurement the RMSE values are 12.01 for component contribution and 9.57 for our model.
<!--This suggests that a single *metabolite* is actually the cause. Would be interesting to look at that distribution-->

Close inspection of the residuals reveals that this difference relects a
consistent improvement in our model's predictions compared with component
contribution. @fig-residual-hist-test-dataset shows the distribution of
residual differences for test measurements between the two models. For most
test measurements our model made better predictions. 

![Distribution of out of sample absolute residual differences](plots/out_of_sample_residual_hist.svg){#fig-residual-hist-test-dataset}

<!--Nice diagram!-->

@fig-test-reaction-residuals shows, for each reaction except
phosphoenolpyruvate mutase, our model's 1%-99% residual interval with respect
to the observed average measurement for that reaction alongside the posterior
predictive mean residual and component contribution residual. This shows the
typical size of the difference in out of sample prediction accuracy between the
two models. It is clear from this plot that our model's posterior predictive
means tended to make better out of sample predictions than component
contribution.

![Comparison of residuals](plots/out_of_sample_reaction_residuals.svg){#fig-test-reaction-residuals}

<!--I think this plot is a little confusing-->
<!--We can look at marginal variance for their predictions as well here. We also want to show that they are underestimating their variance-->
<!--TODO: Add discussion of pairwise variance estimates here-->
<!--TODO: We need to visualise multivariate stuff here-->

# Discussion

## Comparison with state of the art

While our results show that our model improves on the state of the art in out-of-sample predictive accuracy, the most important improvement is to produce a plausible multivariate normal distribution with a full-rank covariance matrix for biochemical formation energies.
We expect that this will allow for better prior distributions in future Bayesian thermokinetic models.

## Limitations

Our model does not take into account adjustments for experimental conditions, instead naiively modelling condition-adjusted measurements reported by eQuilibrator.
This is important as the adjustment for conditions is non-trivial and different plausible modelling assumptions can lead to large changes in adjusted measurements.
See [CITATION HERE] for more discussion of this issue.

We also used the same group decomposition matrix as eQuilibrator.
An alternative group decomposition matrix might yield more accurate results.
[CITE example paper]

Another modelling approach that we did not explore attempts to infer formation energies from chemical structures.
[CITATION].

## Extensions and future work

We plan to augment our model with an application that can generate posterior summaries for unmodelled compounds as described in section @sec-unmodelled-compounds.

# Appendix

## Software

We implemented our project using Python and structured it using the package `bibat` [TODO: INSERT CITATION].

We used the package `equilibrator_api` to fetch the component contribution dataset and `cobrapy` to identify metabolites and reactions in the `e_coli_core` model.
We carried out data cleaning, structuring and validation using `pydantic`, `pandera`, `numpy` and `pandas`.

Our statistical models were written in the probabilistic programming language Stan @carpenterStanProbabilisticProgramming2017.
Sampling was performed using `cmdstan` via the `cmdstanpy` interface.
We used `arviz` to diagnose, structure and store our samples and for visualisation.

All the code used to implement our analysis, and instructions for reproducing it, can be found at <https://github.com/biosustain/dgfreg>.

<!--Love all the credit given here!-->

### QR reparameterisation {#sec-qr-reparameterisation}

Since our model's joint posterior distribution cannot be calculated analytically and has many parameters, we decided to use Markov Chain Monte Carlo to perform posterior inference.
This proved difficult under a naive parameterisation due to the collinearity induced by multiplying the parameter vector $\dgg$ by the group decomposition matrix and then the stoichiometric matrix as shown in equation \eqref{eq-group-contribution-improved}.
Due to these transformations, the information in the measurements relates to the underlying group formation energy parameters through linear projections determined by the matrix $S^\top \mathbf{G}$.
This structure induces a problematic posterior geometry that is difficult for a gradient-based MCMC sampler to traverse.

<!--Specifically, this is because some compounds are only ever relative, right?-->
<!--I don't quite understand why from this-->

In order to address this issue we reparameterised our models using the thin QR
decomposition. Specifically, we found matrices an orthonormal matrix
$Q\in\mathbb{R}^{r\times g}$ and an upper triangular matrix
$R\in\mathbb{R}^{g\times g}$ such that $Q\cdot R = S^\top\cdot \mathbf{G}$. We could
then express our model in terms of auxiliary parameters $\vec{q}$ as shown in
\eqref{eq-qr}.

\begin{align}
Q^\star &= Q \cdot \sqrt{r - 1} \label{eq-qr} \\ 
R^\star &= \frac{R}{\sqrt{r - 1}} \nonumber \\
\dgr &= Q^\star \cdot \vec{q} + S^\top \cdot \vec{\eta} \nonumber
\end{align}

In this parameterisation the formation energy parameters $\dgf$ and
$\dgg$ can be recovered as shown in equation \eqref{eq-qr-recovery}, in
which the superscript $^+$ represents the Moore-Penrose pseudo-inverse:

\begin{align}
\dgg &= (R^\star)^+ \cdot \vec{q} \label{eq-qr-recovery}\\
\dgf &= \mathbf{G} \cdot \dgg + \eta \nonumber
\end{align}

This reparameterisation closely follows the advice on the relevant page of the
Stan user's guide, which can be found
[here](https://github.com/stan-dev/docs/blob/6b68270529344a30821ea20ae4ccebd4c1c60362/src/stan-users-guide/regression.Rmd#L149)
in the exact form in which it was accessed.

<!--Cool trick!-->
<!--This also addresses the equilibrator problem?-->

## MCMC diagnostics

For each of our models, we assessed convergence by running 4 MCMC chains and monitoring the improved $\hat{R}$ statistic proposed in @vehtariRankNormalizationFoldingLocalization2021, verifying that this number was close to 1 for all variables.
We also measured the effective sample size per iteration, ensuring that this was not low enough to indicate improper sampling.
Additionally, we checked that there were no post-warmup divergent transitions.
<!--These should probably be reported-->


### Reformulation using sufficient statistics {#sec-reformulation-using-sufficient-statistics}

<!--Do we need this section at all?-->

By averaging measurements of the same reaction, we can create the mathematically equivalent form of the reactant contribution model shown in equation \eqref{eq-rc-sufficient}.
This model formulation takes advantage of the sufficient statistic that, for a sample of $size$ IID normal random variables $X \sim N(\mu, \sigma)$, the sample mean $\bar{X}$ has distribution $\bar{X}\sim N(\mu, \frac{\sigma}{\sqrt{size}})$.
In equation \eqref{eq-rc-sufficient}, $\bar{y}_j$ is the mean measurement of reaction{j} and $size$ is a function mapping reaction indexes to measurement counts, so that $size(j)$ is the number of measurements of reaction $j$.

\begin{equation}
\bar{y}_j \sim N(\dgr, \frac{\sigma}{\sqrt{size(j)}}) \label{eq-rc-sufficient}
\end{equation}

This formulation is generally computationally preferable because the number of normal distribution densities to evaluate is the number of reactions $r$, which is usually less than the number of measurements $n$.

